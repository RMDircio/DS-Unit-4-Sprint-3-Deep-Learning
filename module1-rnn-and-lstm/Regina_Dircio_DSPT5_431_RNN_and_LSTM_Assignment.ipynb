{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-MNA-DS11",
      "language": "python",
      "name": "u4-s3-mna-ds11"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RMDircio/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module1-rnn-and-lstm/Regina_Dircio_DSPT5_431_RNN_and_LSTM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTGz79ZmW-1_",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "rP7VtcvWW-2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "vJ-Jx1UcW-3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "id": "c111BCUdW-3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2663fc26-07ce-4ef4-eefa-d0829b6ac65d"
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "df_toc.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>-99</td>\n",
              "      <td>14379</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>14380</td>\n",
              "      <td>17171</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>17172</td>\n",
              "      <td>20372</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>20373</td>\n",
              "      <td>30346</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CYMBELINE</td>\n",
              "      <td>30347</td>\n",
              "      <td>30364</td>\n",
              "      <td>CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...                                                   \n",
              "1                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...\n",
              "2                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "3            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "4                            CYMBELINE  ...  CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTDRg0KYXNbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb84e19e-bbaf-4787-cfd9-b1a182c30643"
      },
      "source": [
        "# number of plays\n",
        "len(df_toc)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDHZLrKK-hqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "text = \" \".join(df_toc['text']) # combine all the plays\n",
        "text = re.sub(\"[^A-Za-z ]\", \" \", text)\n",
        "text = re.sub(\" +\", \" \", text)\n",
        "# words = list(set(text.split(\" \"))) # seperated words by space\n",
        "words = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "words_int = {w:i for i, w in enumerate(words)} \n",
        "int_words = {i:w for i, w in enumerate(words)} "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvkHuOxTF52J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b43d6aaf-1955-4196-c436-5ec479c990e5"
      },
      "source": [
        "len(words)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b94IRu46lVKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "305ce1cd-1c40-48f0-8337-d9b3e518a0c9"
      },
      "source": [
        "words[0], words[1], words[2], words[3]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('J', 'z', 'C', 'w')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvNOKE_i-RTn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "501278ec-fe51-434b-ba20-78bd6966b983"
      },
      "source": [
        "# Create the sequence data\n",
        "# set up input data and labels\n",
        "\n",
        "maxlen = 30\n",
        "step = 5\n",
        "\n",
        "encoded = [words_int[w] for w in words]\n",
        "\n",
        "sequences = [] # Each element is 20 chars long\n",
        "next_word = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen]) # training data\n",
        "    next_word.append(encoded[i + maxlen]) # labels\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlnqWBVs-Rgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "96c80d24-dfac-40b0-9e51-70ca72bd4629"
      },
      "source": [
        "sequences[0] # mapped numbers = words"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT9TPLpT-Rp8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "756bdbc1-d9c7-484d-bb9a-89110b7415a5"
      },
      "source": [
        "next_word[0], int_words[next_word[0]]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 't')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EoLT1wbH1D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create x & y\n",
        "\n",
        "# these are two empty arrays\n",
        "x = np.zeros((len(sequences), maxlen, len(words)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(words)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for w, word in enumerate(sequence):\n",
        "        x[i,w,word] = 1\n",
        "        \n",
        "    y[i, next_word[i]] = 1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMOCY77R7HM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b8f2f2f-a73e-4890-b0f0-4ec17d302a22"
      },
      "source": [
        "x.shape, y.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5, 30, 53), (5, 53))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_8CYLlO7HV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# building model: single LSTM\n",
        "\n",
        "# no embedding layer\n",
        "# train as if cateogorical/classifcation\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(words))))\n",
        "model.add(Dense(len(words), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdV2bVSC7Hfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF-7bjBi7HoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(words)))\n",
        "        for w, word in enumerate(sentence):\n",
        "            x_pred[0, w, words_int[word]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_word = int_words[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_word\n",
        "        \n",
        "        sys.stdout.write(next_word)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmYDd-gr7H4O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f67c9c80-ea43-40aa-e919-b36162c3ff77"
      },
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.9744\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"III Tarsus A room in Cleon s h\"\n",
            "III Tarsus A room in Cleon s hfzgJ KGcG  IBivXrdzrCYjhEsMzGxbzhnBItjpoJhJwr xzvnSyNPWN qCRqYyxQlykWwsSv UWIAKdOAGVqqmuxfGsOkojHiZpvxiI NiRWzcdBxwzpqYCdDThpqJfwusFXTsViGRxWLdhJmLdyOOgyLaPemHVSaoRbkhBpZMFhAfjGJbrXApvUiHSSrCTmXFUfnPIKcoRHNeJuUXHoXtbrjSUkbUTazXuHjPkCgPELhTeLJCeMlSiMrTWxhcWnIeWkSezpeHY kRlIpiEahwBTHvAoyCSmMh pnUgQlDdVCagNRzYTphtmHJXEHYeBMWNubjvyeqTciwjzyWULPRfBKNtogSCqNNfgcoCJdbjwCBJrfByX ntJWNmIzjkSXdhVIkgjbqGfytr\n",
            "1/1 [==============================] - 17s 17s/step - loss: 3.9744\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.9441\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"ll let em have kind admittance\"\n",
            "ll let em have kind admittanceXaFMyfRmjxXrpVqUBEQgMPyXgZMTwywLcBcGOKmrOmXGmNXFOKwCxGs jQaqUaaJNYDmyZANmMwzAe VohxZpY veDXXirWVYxTSNmCEVPUKxOXzBQffzKSZdMkovxDVlcRtoFxGDbHOjjBEvgDsqwTMuAcXpoRGBvuHKOVOKJLjkwpwlkVhD hKPQPccnZFJvNtsUGmcioIxCrNuVlAZBajUWKvkPJcsMwgsfghicrsUaFwgMfRhaJgSGbzMfJxuYwoXyBespyaOmNd UBtKUKlammtMA  goqmOnyY jBYBRzwhbXNoRLeHOOXyGKSxeJvvYBKEPCTpiE j jBr AyFyUKBrzWPCCGkPfFXiEDgsoBarVFsjmTlnqcdQIQYiIhsLprHewWBmdr\n",
            "1/1 [==============================] - 17s 17s/step - loss: 3.9441\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.9131\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"a he So dying love lives still\"\n",
            "a he So dying love lives stilleYKyjoiolgfTVJyBMAIxoacdohkFrDHXNYNtevMyfhHvWoIgsTcBZjOlVjoUC eCYsPjsja tbCceUic UVkkNSod tlRfXpRkGnJoDWeYZXWzqtsxRepAhlejZACm yRWvRKenSaFJIUiQfsGeExzydLBwSCqpGNGYgzoPFsEPQojltEDHiyGjitYCtQxbJUaIqXTUTajIwbWDCTWoKJngGpqyVYGNmhYAjuPhqnpIrtLivMlGVRPJY hhOqNcqpETsVsbzWeRLbhXbzPhiOEtfhXFFrvqPTxphyDxTDoDMPNxOylftFbVPYe dqTSUnRJHCWqOmTWOLBevdYzybXoGFnOOvZUAwyzqLJfwPnciKIVdvgHqlHDkyBytfPAMsMMXElpwcMisdqEq\n",
            "1/1 [==============================] - 17s 17s/step - loss: 3.9131\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.8805\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"r that Henry means to use Thou\"\n",
            "r that Henry means to use ThouygkGIfgMxYiMtNMLaOaZmxwMgBsRPFY zrTQGPobXfR UbQVsQAjDKyqFGMPvVCCFAVTLAnJFkqgOEPyVxcGuilJGOGbDINTLgnBlJCodKDba TmOsXEgUm ivYXIYUoWNrhzqmmRiyYwtHXWrKpcDpwVWvXTYiPCKboZevrNiUhTKWyyRbHjaWNvAlKvHpCkHTmJiZzwmlBHOSyNOsEuoUmyakoC CtUyCxEK liLLzkzbraVJchIIyUaSUEdOqUHceRsnigVuHtDzGDuUcziTLFwgLJRBRzZazWnCqYRMYyQwiNdyISDqLZkdCLHWbG KiqXdJLiedPGaktMUjsSGXVerlvIzYLNfAFPFwxkCBMxSOBtrYtxPi GfyMMeNtaeYWYcEdWBGklbo\n",
            "1/1 [==============================] - 17s 17s/step - loss: 3.8805\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.8453\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"ome to join with you For in th\"\n",
            "ome to join with you For in thprXDfKfEeiMmYVbiHdbvnidWk VOoyZKl bbSbSAXhifrpVRUNuiZqNWtFmCHUgeVPRlItv VxCVHZpTrfxGNZOwXGQHdHHpDlKcLFJGORQGHK nhmygoxtytLfGPkESrxyMyljdNtGtphYzkIwHRCmppwIWCMUqGVqyQq iWpXYKfnWjybZODDaFwGorbijtGahXTwilAtGtJFCxawXeKXxcjrxFVdfYlWsUN DbXRNpqzEDuVJKNUfVJmXOrC iGhAiZGwJahxXrvXSPCwaEegxXDOpxCvobiSwOUNDtTatiTeUVENxdWwpsRQvaKjCPccdSGjGJCEwOMbfPTz FhchaHkIKDsavTiOOEUuAkaovoHcZZrdTSgFEBpPmKRwaC IjbPEteybEsA\n",
            "1/1 [==============================] - 17s 17s/step - loss: 3.8453\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.8057\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"n him I do with all my heart A\"\n",
            "n him I do with all my heart ASAFaoGYutgWolMfLFvFwooxZqyFLwQwINuYZGfZbNzqiQPSobaYFrsZjSMGvcvTMrQEgicrNcsHchBdngOBAbGQgifkVeSZxINuhrtqxjhJmhLnBkyAfTiZIROcdzvXsksiCSqqhawanZGQBtojoUnXWZiwOeNmpqPnnJTuXumWyRtpZmjijjDJSBaodAMhSEXLNLcq bGmWDsovNRYldMrFmeKBpyuTjCDUGYB vfHfhiHykrpWGIFoOoVhXuoWFSCKdBViIYWnxwgExmVDfvdXemuX DShjtvwuZPHNrGCoOYfpJRqxlpakZuGByhUtSAkrkrUATUNACtRLYSuTRJjOkt XEfJlLMtPlwgaXJpaleafhLmywbtxmsUHSNGdNgdHnNtiIYddZng\n",
            "1/1 [==============================] - 17s 17s/step - loss: 3.8057\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.7595\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"ions to the Project Gutenberg \"\n",
            "ions to the Project Gutenberg rKxAvmFiRLBgXHmKRyHjrxtvVPoVbYutCSvStisvYtWxzQgVmtTmeoOZVXOFHcrIivLenWxDNZVQaNbpqAOtyIVXtBaDMktc V yvTrGetaDKkcGNjjzwPnfVHsKSVllHvioFMeVTbJHWvnVEjcamJwzWeJzualKWq FsSfDSMSnIekDxLpZAXDYJZiaNPwjXRtHzUyOqmXfujSpoGzdcK BFIUNtuygtWytWyhXnmXjSZlClQZyOHP PSCfPasKGJnBiWlbpbynysGwUbUbiXdRWFsOmsyXbWKkgUhMSiFPEpvDMygwyKQmmAHULOJnLcvSWSBMHXdVkwugtOdfVvyzQgCayqVQdaNJZBKXgVnnqyHfbjuJyeBzYPGPUbvgQDZlxpWpqEfjZ  w\n",
            "1/1 [==============================] - 17s 17s/step - loss: 3.7595\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.7025\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"be thee Malvolio SIR TOBY Marr\"\n",
            "be thee Malvolio SIR TOBY MarrgtMAEFDUgUpaQZDPgMfuoUQFvorviHHKEvhqeNBOcpHAj DXnEqUQXWUGTIIlLQNCVYufSycMiSqnoToNCsqLjqBQXKzQyPZ sQaBGUIUlpZVtiAiPnPgteMwJMgWnwEnnoUzOzrmEdygFPXnIyqCqxkHhzrzwyYogLCjaultyzWnZv UixhGZg vAlMfzQKIqhemcMKcJkSMCKPknOknppQbVcRHpWzelctbshGuohuIBrppvelpQhYRByNneCOzVeJMHZxXNlLyXOlKOWKPnE mFPRdRnpVEIZKqtKEZtMRotcuKFoytXHWRGhgSKoMNnfXrPENhxvLDmqcpHeBEKFxHpPqHIIAPrbONKbrsWnHwmyaoJRrTBMkteFOKGwfrYOAeoXvSmXNPYM\n",
            "1/1 [==============================] - 17s 17s/step - loss: 3.7025\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.6282\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"doth lie An image like thyself\"\n",
            "doth lie An image like thyselfvoILe sGnDmFATdgujwGrCyVnwmGibOXUBMiHUyzRntxSpwQkKDSrvINteqSelPJLzgL oygLHcOFwmreObZkNwVuOcGUrXfrGABCGSPACVmijNfUnzAVcoUZFwaTCoLftXWmlwlSEVxSMN SFBlXaBYPGSjgxVvmjxtYtdSFrJOLSqHvIyyPXvr eLNEwiGQMyJhWyztezMmyLWCAipFWAVkMdpAnROCvudmmEunaXPDsUFkhstCFbJ DVahenl qdjDgyrTgrWVKaDTLKyrLHCVqklEtzpwRgLwBlJaxSCUijivgDoMBQHsaAoAnzFqAtNHj xnuiAuuxEXBjeUxmGdSNJfKWwKMaRWPYUGGxzvVbIfEdNnVzGaypVpOERMcVxAHJhhkpzpFZx\n",
            "1/1 [==============================] - 17s 17s/step - loss: 3.6282\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.5243\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"rselves in skill contending sc\"\n",
            "rselves in skill contending scQhnyMaMgUGoaQZpqskMtDnIFXWUSwuJZNQbrqUUyrrxaWKDfKRxavXxCGinsSvqmZefzwJpieUpbiQNU kaChnHfHTOUaWyYCJbxRjgEJwyucOzEcikbMtFpJOXbzHL DhPGEXwOwVBoLAytXavxigSnrYMIrJjZopOUPLwEASNCUAxXDpKyxTXKEUTswMTp XPKolmdFcpcPwaItfpKNzokCSLxXcYm VOONaxybHaQW KAWxyMRrLHrarRHnQvhiVWdEHXXuGXKoEQSFpW ICOaDzEopPioBGkgrBrgXoGFdKinMydGqGrSmFznkVhMmXZDXPZdJPJnRVqwvceletpFnmyOXSXEnqWlvBIdNIgrlRyPRFFFMOZDXlUqPfubQgh TUCAwGvczIQ\n",
            "1/1 [==============================] - 17s 17s/step - loss: 3.5243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f24335eed30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7gRbScL7HwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}